{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217af916",
   "metadata": {},
   "source": [
    "# Simple Neural Architecture Search (NAS) via Random Search on a 10D Analytical Function\n",
    "\n",
    "This notebook demonstrates an **easy, transparent** form of Neural Architecture Search (NAS) without extra libraries—just TensorFlow/Keras and a bit of Python. We:\n",
    "\n",
    "1. Define a **10-dimensional analytical regression task** (synthetic data with noise).\n",
    "2. Specify a **large search space** (depth, width, activations, optimizers, learning rates, batch sizes, normalization, dropout, etc.).\n",
    "3. Use **Random Search** to sample candidate architectures and hyperparameters.\n",
    "4. Train each candidate briefly and evaluate on a validation set.\n",
    "5. **Select the top 10** architectures by validation performance.\n",
    "6. Retrain the top models longer on train+val and evaluate on the held-out test set.\n",
    "\n",
    "The notebook is heavily commented for a ~45' walkthrough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5ea29",
   "metadata": {},
   "source": [
    "## Why Random Search?\n",
    "Random Search is a surprisingly strong baseline for hyperparameter/architecture tuning:\n",
    "- Scales trivially with search space size.\n",
    "- Parallelizable and easy to reason about.\n",
    "- Often outperforms naive grid search given the same budget (because many hyperparameters are low-sensitivity).\n",
    "\n",
    "Other simple NAS strategies to mention (not implemented here):\n",
    "- **Successive Halving / Hyperband:** Early-stop poor performers aggressively.\n",
    "- **Bayesian Optimization:** Model the response surface to guide sampling.\n",
    "- **Evolutionary Strategies:** Mutate and select architectures over generations.\n",
    "\n",
    "Here we focus on Random Search for **clarity** and **reproducibility**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b1a80",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Imports, versions, and a few utility helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b5a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 15:34:16.232254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762180456.249702   24507 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762180456.254644   24507 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-03 15:34:16.271857: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.12\n",
      "TensorFlow: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, random, json, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "\n",
    "# Reproducibility (best-effort)\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Reduce TF verbosity\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100336b",
   "metadata": {},
   "source": [
    "## 1. Define a 10D analytical function and generate data\n",
    "We create a **nonlinear** function on $x\\in\\mathbb{R}^{10}$ with interactions and noise:\n",
    "\n",
    "$$y = \\sin(x_1) + 0.5\\,x_2^2 - 0.3\\,x_3 x_4 + 0.1\\,\\exp(x_5) + 0.25\\,\\sin(2\\pi x_6) + 0.2\\,\\tanh(x_7+x_8) - 0.15\\,|x_9| + 0.1\\,x_{10} + \\varepsilon$$\n",
    "\n",
    "where $x_i\\sim \\mathcal{N}(0,1)$ and noise $\\varepsilon\\sim \\mathcal{N}(0,\\sigma^2)$ with a modest $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1ff3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (8000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analytical_function(X: np.ndarray, noise_std: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"Compute target y for a 10D input X with shape (n, 10).\"\"\"\n",
    "    x1,x2,x3,x4,x5,x6,x7,x8,x9,x10 = [X[:,i] for i in range(10)]\n",
    "    y = (\n",
    "        np.sin(x1)\n",
    "        + 0.5 * (x2**2)\n",
    "        - 0.3 * (x3 * x4)\n",
    "        + 0.1 * np.exp(0.5 * x5)\n",
    "        + 0.25 * np.sin(2 * np.pi * x6)\n",
    "        + 0.2 * np.tanh(x7 + x8)\n",
    "        - 0.15 * np.abs(x9)\n",
    "        + 0.1 * x10\n",
    "    )\n",
    "    y += np.random.normal(0.0, noise_std, size=y.shape)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def make_dataset(n_train=8000, n_val=1000, n_test=1000, noise_std=0.1):\n",
    "    X_train = np.random.randn(n_train, 10).astype(np.float32)\n",
    "    X_val   = np.random.randn(n_val, 10).astype(np.float32)\n",
    "    X_test  = np.random.randn(n_test, 10).astype(np.float32)\n",
    "    y_train = analytical_function(X_train, noise_std)\n",
    "    y_val   = analytical_function(X_val, noise_std)\n",
    "    y_test  = analytical_function(X_test, noise_std)\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = make_dataset()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85ff8d",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "We standardize inputs and targets (fit on train, apply to val/test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0bed030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (8000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train.reshape(-1,1))\n",
    "\n",
    "X_train_s = x_scaler.transform(X_train).astype(np.float32)\n",
    "X_val_s   = x_scaler.transform(X_val).astype(np.float32)\n",
    "X_test_s  = x_scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "y_train_s = y_scaler.transform(y_train.reshape(-1,1)).astype(np.float32).reshape(-1)\n",
    "y_val_s   = y_scaler.transform(y_val.reshape(-1,1)).astype(np.float32).reshape(-1)\n",
    "y_test_s  = y_scaler.transform(y_test.reshape(-1,1)).astype(np.float32).reshape(-1)\n",
    "\n",
    "X_train_s.shape, y_train_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2dfe00",
   "metadata": {},
   "source": [
    "## 2. Define the search space\n",
    "We treat the following as tunable hyperparameters:\n",
    "- **depth**: number of hidden layers (e.g., 1–6)\n",
    "- **width**: units per hidden layer (e.g., 32–512, powers of 2)\n",
    "- **activation**: `relu`, `gelu`, `tanh`, `elu`\n",
    "- **batch normalization**: on/off\n",
    "- **dropout rate**: 0.0–0.5\n",
    "- **optimizer**: `adam`, `rmsprop`, `sgd`\n",
    "- **learning rate**: log-uniform in [1e-4, 1e-1]\n",
    "- **batch size**: {64, 128, 256}\n",
    "\n",
    "You can add more (residuals, weight decay, activation per layer, etc.), but this already creates a large space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66277082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 1,\n",
       " 'width': 128,\n",
       " 'activation': 'relu',\n",
       " 'batchnorm': True,\n",
       " 'dropout': 0.2,\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.0005879105777682459,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPTH_CHOICES = list(range(1, 7))\n",
    "WIDTH_CHOICES = [32, 64, 128, 256, 512]\n",
    "ACT_CHOICES   = [\"relu\", \"gelu\", \"tanh\", \"elu\"]\n",
    "BN_CHOICES    = [False, True]\n",
    "DROPOUT_CHOICES = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "OPT_CHOICES   = [\"adam\", \"rmsprop\", \"sgd\"]\n",
    "LR_MIN, LR_MAX = 1e-4, 1e-1  # log-uniform range\n",
    "BATCH_CHOICES = [64, 128, 256]\n",
    "\n",
    "def sample_config() -> Dict[str, Any]:\n",
    "    depth = random.choice(DEPTH_CHOICES)\n",
    "    width = random.choice(WIDTH_CHOICES)\n",
    "    act   = random.choice(ACT_CHOICES)\n",
    "    bn    = random.choice(BN_CHOICES)\n",
    "    dr    = random.choice(DROPOUT_CHOICES)\n",
    "    opt   = random.choice(OPT_CHOICES)\n",
    "    # log-uniform LR\n",
    "    lr    = 10 ** np.random.uniform(np.log10(LR_MIN), np.log10(LR_MAX))\n",
    "    bs    = random.choice(BATCH_CHOICES)\n",
    "    return {\n",
    "        \"depth\": depth,\n",
    "        \"width\": width,\n",
    "        \"activation\": act,\n",
    "        \"batchnorm\": bn,\n",
    "        \"dropout\": float(dr),\n",
    "        \"optimizer\": opt,\n",
    "        \"learning_rate\": float(lr),\n",
    "        \"batch_size\": bs,\n",
    "    }\n",
    "\n",
    "sample_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c8810",
   "metadata": {},
   "source": [
    "## 3. Model builder\n",
    "Given a sampled configuration, build and compile a Keras MLP for regression. We keep the head linear for standardized targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8baff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 15:34:45.850098: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_regressor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mlp_regressor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">802,305</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m802,305\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">798,209</span> (3.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m798,209\u001b[0m (3.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,096\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(config: Dict[str, Any], input_dim: int = 10) -> keras.Model:\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "    for _ in range(config[\"depth\"]):\n",
    "        x = layers.Dense(config[\"width\"], activation=None)(x)\n",
    "        if config[\"batchnorm\"]:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(config[\"activation\"])(x)\n",
    "        if config[\"dropout\"] > 0:\n",
    "            x = layers.Dropout(config[\"dropout\"])(x)\n",
    "    outputs = layers.Dense(1, activation=None)(x)  # linear head for standardized y\n",
    "    model = keras.Model(inputs, outputs, name=\"mlp_regressor\")\n",
    "\n",
    "    opt_name = config[\"optimizer\"]\n",
    "    lr = config[\"learning_rate\"]\n",
    "    if opt_name == \"adam\":\n",
    "        opt = keras.optimizers.Adam(lr)\n",
    "    elif opt_name == \"rmsprop\":\n",
    "        opt = keras.optimizers.RMSprop(lr)\n",
    "    else:\n",
    "        opt = keras.optimizers.SGD(lr, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=\"mse\", metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")])\n",
    "    return model\n",
    "\n",
    "build_model(sample_config()).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a217cb",
   "metadata": {},
   "source": [
    "## 4. Random Search loop\n",
    "We run a budgeted random search:\n",
    "- Sample `N_TRIALS` configurations.\n",
    "- Train each for a small number of epochs (`EPOCHS_PER_TRIAL`).\n",
    "- Track validation loss.\n",
    "\n",
    "We also add early stopping to avoid wasting time on clearly underperforming trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198e2d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 01/40: val_mse=0.1064 | cfg={'depth': 2, 'width': 32, 'activation': 'elu', 'batchnorm': False, 'dropout': 0.4, 'optimizer': 'rmsprop', 'learning_rate': 0.015118782763459562, 'batch_size': 64}\n",
      "Trial 02/40: val_mse=0.3486 | cfg={'depth': 1, 'width': 32, 'activation': 'gelu', 'batchnorm': False, 'dropout': 0.0, 'optimizer': 'rmsprop', 'learning_rate': 0.00013823872102978758, 'batch_size': 128}\n",
      "Trial 03/40: val_mse=0.1169 | cfg={'depth': 3, 'width': 256, 'activation': 'relu', 'batchnorm': True, 'dropout': 0.2, 'optimizer': 'sgd', 'learning_rate': 0.00018719517101921604, 'batch_size': 128}\n",
      "Trial 04/40: val_mse=0.7197 | cfg={'depth': 3, 'width': 32, 'activation': 'elu', 'batchnorm': True, 'dropout': 0.5, 'optimizer': 'sgd', 'learning_rate': 0.0003464943675993339, 'batch_size': 256}\n",
      "Trial 05/40: val_mse=0.1386 | cfg={'depth': 6, 'width': 256, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.5, 'optimizer': 'adam', 'learning_rate': 0.010028820208697593, 'batch_size': 256}\n",
      "Trial 06/40: val_mse=0.1469 | cfg={'depth': 6, 'width': 256, 'activation': 'elu', 'batchnorm': True, 'dropout': 0.0, 'optimizer': 'adam', 'learning_rate': 0.03522437027512884, 'batch_size': 256}\n",
      "Trial 07/40: val_mse=0.0819 | cfg={'depth': 2, 'width': 256, 'activation': 'relu', 'batchnorm': True, 'dropout': 0.3, 'optimizer': 'sgd', 'learning_rate': 0.01988465950481001, 'batch_size': 256}\n",
      "Trial 08/40: val_mse=0.0912 | cfg={'depth': 5, 'width': 256, 'activation': 'elu', 'batchnorm': True, 'dropout': 0.0, 'optimizer': 'adam', 'learning_rate': 0.0005246059121290639, 'batch_size': 64}\n",
      "Trial 09/40: val_mse=0.0673 | cfg={'depth': 6, 'width': 128, 'activation': 'elu', 'batchnorm': True, 'dropout': 0.0, 'optimizer': 'adam', 'learning_rate': 0.0017329234819236073, 'batch_size': 256}\n",
      "Trial 10/40: val_mse=0.1431 | cfg={'depth': 1, 'width': 512, 'activation': 'elu', 'batchnorm': False, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.0367777354104586, 'batch_size': 256}\n",
      "Trial 11/40: val_mse=0.0973 | cfg={'depth': 3, 'width': 256, 'activation': 'relu', 'batchnorm': True, 'dropout': 0.3, 'optimizer': 'rmsprop', 'learning_rate': 0.015135490097391808, 'batch_size': 64}\n",
      "Trial 12/40: val_mse=0.2587 | cfg={'depth': 6, 'width': 64, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.5, 'optimizer': 'adam', 'learning_rate': 0.018916922891321433, 'batch_size': 256}\n",
      "Trial 13/40: val_mse=0.0726 | cfg={'depth': 4, 'width': 128, 'activation': 'gelu', 'batchnorm': True, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.002769144926910496, 'batch_size': 256}\n",
      "Trial 14/40: val_mse=0.6930 | cfg={'depth': 6, 'width': 32, 'activation': 'tanh', 'batchnorm': True, 'dropout': 0.5, 'optimizer': 'sgd', 'learning_rate': 0.0012760755616076863, 'batch_size': 256}\n",
      "Trial 15/40: val_mse=0.0778 | cfg={'depth': 5, 'width': 512, 'activation': 'gelu', 'batchnorm': True, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.0012489372410308885, 'batch_size': 256}\n",
      "Trial 16/40: val_mse=0.1002 | cfg={'depth': 2, 'width': 128, 'activation': 'tanh', 'batchnorm': True, 'dropout': 0.0, 'optimizer': 'sgd', 'learning_rate': 0.017316849068970724, 'batch_size': 64}\n",
      "Trial 17/40: val_mse=0.6271 | cfg={'depth': 1, 'width': 64, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.0, 'optimizer': 'sgd', 'learning_rate': 0.0001064501027865259, 'batch_size': 128}\n",
      "Trial 18/40: val_mse=0.1040 | cfg={'depth': 5, 'width': 512, 'activation': 'gelu', 'batchnorm': False, 'dropout': 0.3, 'optimizer': 'rmsprop', 'learning_rate': 0.0001562280618972688, 'batch_size': 256}\n",
      "Trial 19/40: val_mse=0.2409 | cfg={'depth': 4, 'width': 64, 'activation': 'gelu', 'batchnorm': False, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.0011343193001420713, 'batch_size': 128}\n",
      "Trial 20/40: val_mse=0.1183 | cfg={'depth': 3, 'width': 256, 'activation': 'tanh', 'batchnorm': True, 'dropout': 0.1, 'optimizer': 'rmsprop', 'learning_rate': 0.003943278444810034, 'batch_size': 128}\n",
      "Trial 21/40: val_mse=0.1046 | cfg={'depth': 1, 'width': 256, 'activation': 'elu', 'batchnorm': True, 'dropout': 0.1, 'optimizer': 'sgd', 'learning_rate': 0.012604143578552402, 'batch_size': 128}\n",
      "Trial 22/40: val_mse=0.0766 | cfg={'depth': 3, 'width': 32, 'activation': 'tanh', 'batchnorm': True, 'dropout': 0.0, 'optimizer': 'rmsprop', 'learning_rate': 0.00376251926150146, 'batch_size': 64}\n",
      "Trial 23/40: val_mse=0.1364 | cfg={'depth': 4, 'width': 512, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.5, 'optimizer': 'rmsprop', 'learning_rate': 0.0007250489433021553, 'batch_size': 128}\n",
      "Trial 24/40: val_mse=0.0887 | cfg={'depth': 5, 'width': 128, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.019146423139374598, 'batch_size': 64}\n",
      "Trial 25/40: val_mse=0.4255 | cfg={'depth': 3, 'width': 128, 'activation': 'gelu', 'batchnorm': False, 'dropout': 0.3, 'optimizer': 'sgd', 'learning_rate': 0.0006767516396275879, 'batch_size': 256}\n",
      "Trial 26/40: val_mse=0.1548 | cfg={'depth': 6, 'width': 256, 'activation': 'gelu', 'batchnorm': False, 'dropout': 0.2, 'optimizer': 'rmsprop', 'learning_rate': 0.0065549629531966675, 'batch_size': 64}\n",
      "Trial 27/40: val_mse=0.0883 | cfg={'depth': 2, 'width': 512, 'activation': 'gelu', 'batchnorm': True, 'dropout': 0.3, 'optimizer': 'rmsprop', 'learning_rate': 0.016457003451876142, 'batch_size': 64}\n",
      "Trial 28/40: val_mse=0.0944 | cfg={'depth': 5, 'width': 512, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.0014943674695708912, 'batch_size': 256}\n",
      "Trial 29/40: val_mse=0.0874 | cfg={'depth': 4, 'width': 512, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.3, 'optimizer': 'adam', 'learning_rate': 0.0003147363139341062, 'batch_size': 64}\n",
      "Trial 30/40: val_mse=0.1918 | cfg={'depth': 1, 'width': 32, 'activation': 'elu', 'batchnorm': True, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.0014524479141435217, 'batch_size': 64}\n",
      "Trial 31/40: val_mse=0.0925 | cfg={'depth': 4, 'width': 128, 'activation': 'gelu', 'batchnorm': True, 'dropout': 0.0, 'optimizer': 'rmsprop', 'learning_rate': 0.00029299403041503104, 'batch_size': 256}\n",
      "Trial 32/40: val_mse=0.1052 | cfg={'depth': 1, 'width': 128, 'activation': 'gelu', 'batchnorm': True, 'dropout': 0.1, 'optimizer': 'rmsprop', 'learning_rate': 0.02537232047946702, 'batch_size': 64}\n",
      "Trial 33/40: val_mse=0.0907 | cfg={'depth': 4, 'width': 256, 'activation': 'gelu', 'batchnorm': True, 'dropout': 0.0, 'optimizer': 'rmsprop', 'learning_rate': 0.05776457884902587, 'batch_size': 64}\n",
      "Trial 34/40: val_mse=0.1299 | cfg={'depth': 1, 'width': 64, 'activation': 'relu', 'batchnorm': True, 'dropout': 0.2, 'optimizer': 'sgd', 'learning_rate': 0.010279759728239489, 'batch_size': 256}\n",
      "Trial 35/40: val_mse=0.2103 | cfg={'depth': 3, 'width': 128, 'activation': 'tanh', 'batchnorm': False, 'dropout': 0.3, 'optimizer': 'adam', 'learning_rate': 0.0003518182222111109, 'batch_size': 64}\n",
      "Trial 36/40: val_mse=0.0569 | cfg={'depth': 3, 'width': 32, 'activation': 'gelu', 'batchnorm': True, 'dropout': 0.1, 'optimizer': 'rmsprop', 'learning_rate': 0.007025191608143858, 'batch_size': 64}\n",
      "Trial 37/40: val_mse=0.0467 | cfg={'depth': 1, 'width': 128, 'activation': 'relu', 'batchnorm': False, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.009248357992775449, 'batch_size': 128}\n",
      "Trial 38/40: val_mse=0.1040 | cfg={'depth': 4, 'width': 32, 'activation': 'relu', 'batchnorm': False, 'dropout': 0.0, 'optimizer': 'rmsprop', 'learning_rate': 0.012626420586839148, 'batch_size': 256}\n",
      "Trial 39/40: val_mse=0.1823 | cfg={'depth': 4, 'width': 64, 'activation': 'gelu', 'batchnorm': False, 'dropout': 0.3, 'optimizer': 'rmsprop', 'learning_rate': 0.0001881851602592445, 'batch_size': 256}\n",
      "Trial 40/40: val_mse=0.1336 | cfg={'depth': 2, 'width': 32, 'activation': 'relu', 'batchnorm': False, 'dropout': 0.0, 'optimizer': 'adam', 'learning_rate': 0.0003001011187909476, 'batch_size': 128}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>depth</th>\n",
       "      <th>width</th>\n",
       "      <th>activation</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>128</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>0.180416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>64</td>\n",
       "      <td>0.056885</td>\n",
       "      <td>0.193722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>elu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>256</td>\n",
       "      <td>0.067345</td>\n",
       "      <td>0.205303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>256</td>\n",
       "      <td>0.072618</td>\n",
       "      <td>0.213007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>64</td>\n",
       "      <td>0.076624</td>\n",
       "      <td>0.218028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>256</td>\n",
       "      <td>0.077786</td>\n",
       "      <td>0.218548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.019885</td>\n",
       "      <td>256</td>\n",
       "      <td>0.081898</td>\n",
       "      <td>0.230770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>tanh</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>64</td>\n",
       "      <td>0.087425</td>\n",
       "      <td>0.224040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>64</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.239990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.019146</td>\n",
       "      <td>64</td>\n",
       "      <td>0.088703</td>\n",
       "      <td>0.231990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial  depth  width activation  batchnorm  dropout optimizer  \\\n",
       "0     37      1    128       relu      False      0.1      adam   \n",
       "1     36      3     32       gelu       True      0.1   rmsprop   \n",
       "2      9      6    128        elu       True      0.0      adam   \n",
       "3     13      4    128       gelu       True      0.4      adam   \n",
       "4     22      3     32       tanh       True      0.0   rmsprop   \n",
       "5     15      5    512       gelu       True      0.4      adam   \n",
       "6      7      2    256       relu       True      0.3       sgd   \n",
       "7     29      4    512       tanh      False      0.3      adam   \n",
       "8     27      2    512       gelu       True      0.3   rmsprop   \n",
       "9     24      5    128       tanh      False      0.1      adam   \n",
       "\n",
       "   learning_rate  batch_size   val_mse   val_mae  \n",
       "0       0.009248         128  0.046711  0.180416  \n",
       "1       0.007025          64  0.056885  0.193722  \n",
       "2       0.001733         256  0.067345  0.205303  \n",
       "3       0.002769         256  0.072618  0.213007  \n",
       "4       0.003763          64  0.076624  0.218028  \n",
       "5       0.001249         256  0.077786  0.218548  \n",
       "6       0.019885         256  0.081898  0.230770  \n",
       "7       0.000315          64  0.087425  0.224040  \n",
       "8       0.016457          64  0.088325  0.239990  \n",
       "9       0.019146          64  0.088703  0.231990  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Search budget (tweak to speed up/slow down the demo) ---\n",
    "N_TRIALS = 40\n",
    "EPOCHS_PER_TRIAL = 20\n",
    "PATIENCE = 5\n",
    "\n",
    "results = []\n",
    "\n",
    "for t in range(1, N_TRIALS + 1):\n",
    "    cfg = sample_config()\n",
    "    model = build_model(cfg)\n",
    "    early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True)\n",
    "    hist = model.fit(\n",
    "        X_train_s, y_train_s,\n",
    "        validation_data=(X_val_s, y_val_s),\n",
    "        epochs=EPOCHS_PER_TRIAL,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        verbose=0,\n",
    "        callbacks=[early],\n",
    "    )\n",
    "    val_mse = float(min(hist.history[\"val_loss\"]))\n",
    "    val_mae = float(min(hist.history[\"val_mae\"]))\n",
    "    results.append({\"trial\": t, **cfg, \"val_mse\": val_mse, \"val_mae\": val_mae})\n",
    "    print(f\"Trial {t:02d}/{N_TRIALS}: val_mse={val_mse:.4f} | cfg={cfg}\")\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(\"val_mse\").reset_index(drop=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f07259",
   "metadata": {},
   "source": [
    "### Visualize the search results\n",
    "A quick look at how validation error varies over model choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc937d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>depth</th>\n",
       "      <th>width</th>\n",
       "      <th>activation</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.500000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>197.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.173785</td>\n",
       "      <td>0.295846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.690452</td>\n",
       "      <td>1.705008</td>\n",
       "      <td>168.377598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>86.958876</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.110405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>0.180416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.090208</td>\n",
       "      <td>0.231965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.105815</td>\n",
       "      <td>0.256834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015123</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.161706</td>\n",
       "      <td>0.313543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057765</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.719706</td>\n",
       "      <td>0.634488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trial      depth       width activation batchnorm    dropout  \\\n",
       "count   40.000000  40.000000   40.000000         40        40  40.000000   \n",
       "unique        NaN        NaN         NaN          4         2        NaN   \n",
       "top           NaN        NaN         NaN       gelu      True        NaN   \n",
       "freq          NaN        NaN         NaN         13        21        NaN   \n",
       "mean    20.500000   3.375000  197.600000        NaN       NaN   0.222500   \n",
       "std     11.690452   1.705008  168.377598        NaN       NaN   0.181853   \n",
       "min      1.000000   1.000000   32.000000        NaN       NaN   0.000000   \n",
       "25%     10.750000   2.000000   64.000000        NaN       NaN   0.000000   \n",
       "50%     20.500000   3.000000  128.000000        NaN       NaN   0.250000   \n",
       "75%     30.250000   5.000000  256.000000        NaN       NaN   0.400000   \n",
       "max     40.000000   6.000000  512.000000        NaN       NaN   0.500000   \n",
       "\n",
       "       optimizer  learning_rate  batch_size    val_mse    val_mae  \n",
       "count         40      40.000000   40.000000  40.000000  40.000000  \n",
       "unique         3            NaN         NaN        NaN        NaN  \n",
       "top      rmsprop            NaN         NaN        NaN        NaN  \n",
       "freq          15            NaN         NaN        NaN        NaN  \n",
       "mean         NaN       0.009215  160.000000   0.173785   0.295846  \n",
       "std          NaN       0.012485   86.958876   0.164636   0.110405  \n",
       "min          NaN       0.000106   64.000000   0.046711   0.180416  \n",
       "25%          NaN       0.000481   64.000000   0.090208   0.231965  \n",
       "50%          NaN       0.003266  128.000000   0.105815   0.256834  \n",
       "75%          NaN       0.015123  256.000000   0.161706   0.313543  \n",
       "max          NaN       0.057765  256.000000   0.719706   0.634488  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(df.index+1, df[\"val_mse\"], marker='o', linestyle='-')\n",
    "plt.xlabel('Rank (1=best)')\n",
    "plt.ylabel('Validation MSE')\n",
    "plt.title('Random Search Results (sorted by val_mse)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efa839",
   "metadata": {},
   "source": [
    "## 5. Select the Top-10 configurations\n",
    "We extract the top-10 by validation MSE for a deeper retraining pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2192ef74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>depth</th>\n",
       "      <th>width</th>\n",
       "      <th>activation</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>128</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>0.180416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>64</td>\n",
       "      <td>0.056885</td>\n",
       "      <td>0.193722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>elu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>256</td>\n",
       "      <td>0.067345</td>\n",
       "      <td>0.205303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>256</td>\n",
       "      <td>0.072618</td>\n",
       "      <td>0.213007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>64</td>\n",
       "      <td>0.076624</td>\n",
       "      <td>0.218028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial  depth  width activation  batchnorm  dropout optimizer  \\\n",
       "0     37      1    128       relu      False      0.1      adam   \n",
       "1     36      3     32       gelu       True      0.1   rmsprop   \n",
       "2      9      6    128        elu       True      0.0      adam   \n",
       "3     13      4    128       gelu       True      0.4      adam   \n",
       "4     22      3     32       tanh       True      0.0   rmsprop   \n",
       "\n",
       "   learning_rate  batch_size   val_mse   val_mae  \n",
       "0       0.009248         128  0.046711  0.180416  \n",
       "1       0.007025          64  0.056885  0.193722  \n",
       "2       0.001733         256  0.067345  0.205303  \n",
       "3       0.002769         256  0.072618  0.213007  \n",
       "4       0.003763          64  0.076624  0.218028  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP_K = 5\n",
    "topk = df.head(TOP_K).copy()\n",
    "topk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f38a2",
   "metadata": {},
   "source": [
    "## 6. Retrain Top-10 on Train+Val and Evaluate on Test\n",
    "We join train and val, retrain each model for more epochs, and evaluate test performance. We also map predictions back to the original target scale for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24094062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>width</th>\n",
       "      <th>activation</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>test_mse_std</th>\n",
       "      <th>test_mae_std</th>\n",
       "      <th>test_rmse_orig</th>\n",
       "      <th>test_mae_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>128</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>0.175059</td>\n",
       "      <td>0.229041</td>\n",
       "      <td>0.186242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>64</td>\n",
       "      <td>0.059418</td>\n",
       "      <td>0.191880</td>\n",
       "      <td>0.259330</td>\n",
       "      <td>0.204139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>elu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>256</td>\n",
       "      <td>0.063105</td>\n",
       "      <td>0.197965</td>\n",
       "      <td>0.267255</td>\n",
       "      <td>0.210612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>256</td>\n",
       "      <td>0.075190</td>\n",
       "      <td>0.204652</td>\n",
       "      <td>0.291726</td>\n",
       "      <td>0.217726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>64</td>\n",
       "      <td>0.080217</td>\n",
       "      <td>0.207794</td>\n",
       "      <td>0.301321</td>\n",
       "      <td>0.221069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  width activation  batchnorm  dropout optimizer  learning_rate  \\\n",
       "0      1    128       relu      False      0.1      adam       0.009248   \n",
       "1      3     32       gelu       True      0.1   rmsprop       0.007025   \n",
       "2      6    128        elu       True      0.0      adam       0.001733   \n",
       "3      4    128       gelu       True      0.4      adam       0.002769   \n",
       "4      3     32       tanh       True      0.0   rmsprop       0.003763   \n",
       "\n",
       "   batch_size  test_mse_std  test_mae_std  test_rmse_orig  test_mae_orig  \n",
       "0         128      0.046349      0.175059        0.229041       0.186242  \n",
       "1          64      0.059418      0.191880        0.259330       0.204139  \n",
       "2         256      0.063105      0.197965        0.267255       0.210612  \n",
       "3         256      0.075190      0.204652        0.291726       0.217726  \n",
       "4          64      0.080217      0.207794        0.301321       0.221069  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final = np.concatenate([X_train_s, X_val_s], axis=0)\n",
    "y_final = np.concatenate([y_train_s, y_val_s], axis=0)\n",
    "\n",
    "FINAL_EPOCHS = 40 # larger than origial \n",
    "final_records = []\n",
    "\n",
    "for i, row in topk.iterrows():\n",
    "    cfg = {k: row[k] for k in [\n",
    "        \"depth\",\"width\",\"activation\",\"batchnorm\",\"dropout\",\"optimizer\",\"learning_rate\",\"batch_size\"\n",
    "    ]}\n",
    "    model = build_model(cfg)\n",
    "    early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "    model.fit(\n",
    "        X_final, y_final,\n",
    "        validation_data=(X_test_s, y_test_s),  # monitor generalization\n",
    "        epochs=FINAL_EPOCHS,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        verbose=0,\n",
    "        callbacks=[early],\n",
    "    )\n",
    "    # Evaluate on test in standardized space\n",
    "    test_mse, test_mae = model.evaluate(X_test_s, y_test_s, verbose=0)\n",
    "\n",
    "    # Convert metrics to original y-scale\n",
    "    # If y' = (y - mu)/sigma, then MSE_y = sigma^2 * MSE_y'\n",
    "    sigma_y = float(y_scaler.scale_[0])\n",
    "    test_rmse_orig = math.sqrt(test_mse) * sigma_y\n",
    "    test_mae_orig  = test_mae * sigma_y\n",
    "\n",
    "    final_records.append({\n",
    "        **cfg,\n",
    "        \"test_mse_std\": float(test_mse),\n",
    "        \"test_mae_std\": float(test_mae),\n",
    "        \"test_rmse_orig\": float(test_rmse_orig),\n",
    "        \"test_mae_orig\": float(test_mae_orig),\n",
    "    })\n",
    "\n",
    "final_df = pd.DataFrame(final_records).sort_values(\"test_rmse_orig\").reset_index(drop=True)\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ee18a",
   "metadata": {},
   "source": [
    "### Compare Top-10 Test Performance\n",
    "We show the distribution of test RMSE (original scale) across the top-10 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b80f55e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>width</th>\n",
       "      <th>activation</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>test_mse_std</th>\n",
       "      <th>test_mae_std</th>\n",
       "      <th>test_rmse_orig</th>\n",
       "      <th>test_mae_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>128</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>0.175059</td>\n",
       "      <td>0.229041</td>\n",
       "      <td>0.186242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>64</td>\n",
       "      <td>0.059418</td>\n",
       "      <td>0.191880</td>\n",
       "      <td>0.259330</td>\n",
       "      <td>0.204139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>elu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>256</td>\n",
       "      <td>0.063105</td>\n",
       "      <td>0.197965</td>\n",
       "      <td>0.267255</td>\n",
       "      <td>0.210612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>gelu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>256</td>\n",
       "      <td>0.075190</td>\n",
       "      <td>0.204652</td>\n",
       "      <td>0.291726</td>\n",
       "      <td>0.217726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>64</td>\n",
       "      <td>0.080217</td>\n",
       "      <td>0.207794</td>\n",
       "      <td>0.301321</td>\n",
       "      <td>0.221069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  width activation  batchnorm  dropout optimizer  learning_rate  \\\n",
       "0      1    128       relu      False      0.1      adam       0.009248   \n",
       "1      3     32       gelu       True      0.1   rmsprop       0.007025   \n",
       "2      6    128        elu       True      0.0      adam       0.001733   \n",
       "3      4    128       gelu       True      0.4      adam       0.002769   \n",
       "4      3     32       tanh       True      0.0   rmsprop       0.003763   \n",
       "\n",
       "   batch_size  test_mse_std  test_mae_std  test_rmse_orig  test_mae_orig  \n",
       "0         128      0.046349      0.175059        0.229041       0.186242  \n",
       "1          64      0.059418      0.191880        0.259330       0.204139  \n",
       "2         256      0.063105      0.197965        0.267255       0.210612  \n",
       "3         256      0.075190      0.204652        0.291726       0.217726  \n",
       "4          64      0.080217      0.207794        0.301321       0.221069  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(range(1, len(final_df)+1), final_df[\"test_rmse_orig\"])  # no color specified per instructions\n",
    "plt.xlabel('Top-10 Model Rank (1=best)')\n",
    "plt.ylabel('Test RMSE (original y scale)')\n",
    "plt.title('Top-10 Architectures: Test RMSE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cc8dc",
   "metadata": {},
   "source": [
    "## 7. Introspection: What worked well?\n",
    "We can check which hyperparameters appear in the winning models. This is not causal inference—just a quick descriptive analysis to support discussion during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937d7b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth\n",
       "3    2\n",
       "1    1\n",
       "6    1\n",
       "4    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "width\n",
       "128    3\n",
       "32     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "activation\n",
       "gelu    2\n",
       "relu    1\n",
       "elu     1\n",
       "tanh    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "batchnorm\n",
       "True     4\n",
       "False    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dropout\n",
       "0.1    2\n",
       "0.0    2\n",
       "0.4    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "optimizer\n",
       "adam       3\n",
       "rmsprop    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "batch_size\n",
       "64     2\n",
       "256    2\n",
       "128    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_cols = [\"depth\",\"width\",\"activation\",\"batchnorm\",\"dropout\",\"optimizer\",\"batch_size\"]\n",
    "for col in summary_cols:\n",
    "    display(final_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69ffff",
   "metadata": {},
   "source": [
    "## 8. Save Artifacts (Optional)\n",
    "We save the top-10 leaderboard and the full random-search table to CSV for later inspection. You can also save models if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d770c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"nas_outputs\", exist_ok=True)\n",
    "df.to_csv(\"nas_outputs/random_search_all_trials.csv\", index=False)\n",
    "final_df.to_csv(\"nas_outputs/top10_retrained_test_metrics.csv\", index=False)\n",
    "print(\"Saved:\")\n",
    "print(\" - nas_outputs/random_search_all_trials.csv\")\n",
    "print(\" - nas_outputs/top10_retrained_test_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765b6d4",
   "metadata": {},
   "source": [
    "## 9. Teaching Notes & Extensions\n",
    "- **Budget vs. space:** Increase `N_TRIALS` or `EPOCHS_PER_TRIAL` for better results; decrease for speed.\n",
    "- **Early stopping:** Helps avoid wasted compute on poor configs.\n",
    "- **Alternative strategies:**\n",
    "  - *Successive Halving / Hyperband:* Train all a little, keep the best, allocate more epochs iteratively.\n",
    "  - *Bayesian Optimization:* Use a surrogate model (e.g., Gaussian Process, TPE) to guide sampling.\n",
    "  - *Evolutionary Algorithms:* Maintain a population of architectures, select/mutate/crossover.\n",
    "- **Search space design:** Consider residual connections, per-layer activations, weight decay, spectral norm, etc.\n",
    "- **Metrics:** We use MSE/MAE. For noisy targets, RMSE in original units (back-transformed) is easier to interpret.\n",
    "- **Reproducibility:** Fix seeds, log versions, save artifacts, record configs for each trial.\n",
    "- **Caveat:** Random Search is strong but not magic—if the space is huge and the budget is tiny, you may under-sample good regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7652e",
   "metadata": {},
   "source": [
    "---\n",
    "**End of notebook.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
